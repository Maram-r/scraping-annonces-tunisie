
# Tunisie Annonce Scraper API

Ce projet est une **API REST avec FastAPI** qui permet de lancer un **scraping d'annonces immobiliÃ¨res** depuis le site [tunisie-annonce.com](http://www.tunisie-annonce.com), et de consulter les donnÃ©es collectÃ©es via des endpoints.

---

##  Arborescence du projet

```
projet-scraping-api/
â”‚
â”œâ”€â”€ scraping/
â”‚   â””â”€â”€ scraper.py           # Script principal de scraping avec Selenium
â”‚
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py              # API FastAPI avec les endpoints
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ annonces.json        # (gÃ©nÃ©rÃ©) Fichier JSON contenant les rÃ©sultats du scraping
â”‚
â”œâ”€â”€ chromedriver/           
â”‚   â””â”€â”€ chromedriver.exe     # WebDriver pour Google Chrome
â”‚
â”œâ”€â”€ venv/                    # Environnement virtuel Python
â”‚
â””â”€â”€ requirements.txt         # Liste des dÃ©pendances
```

---

##  PrÃ©requis

- Python 3.10 ou +
- Google Chrome installÃ©
- [ChromeDriver](https://sites.google.com/chromium.org/driver/) (dÃ©jÃ  inclus ici)
- AccÃ¨s Internet

---

## ğŸ”§ Installation

1. **Cloner le projet** :

```bash
git clone https://github.com/Maram-r/scraping-annonces-tunisie.git
cd projet-scraping-api
```

2. **Activer lâ€™environnement virtuel** :

Sous Windows :
```bash
venv\Scripts\activate
```

Sous Mac/Linux :
```bash
source venv/bin/activate
```

3. **Installer les dÃ©pendances** :

```bash
pip install -r requirements.txt
```

> Si tu nâ€™as pas encore de `requirements.txt`, crÃ©e-le avec :
```bash
pip freeze > requirements.txt
```

Exemple de contenu :
```
fastapi
uvicorn
selenium
beautifulsoup4
```

---

## ğŸš€ Lancer lâ€™API

Assure-toi dâ€™Ãªtre dans lâ€™environnement virtuel, puis lance :

```bash
uvicorn api.main:app --reload
```

Tu devrais voir :

```
Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
```

---

##  Endpoints de lâ€™API

###  `POST /scrape`

Lance une session de scraping.

- **ParamÃ¨tre (query)** : `n_pages` (int, optionnel) â†’ Nombre de pages Ã  scraper (par dÃ©faut : 1)

Exemple avec `curl` :
```bash
curl -X POST "http://127.0.0.1:8000/scrape?n_pages=2"
```

###  `GET /annonces`

Retourne toutes les annonces collectÃ©es dans `data/annonces.json`.

Exemple :
```bash
curl http://127.0.0.1:8000/annonces
```

---

##  Tester dans Swagger UI

Va sur :
```
http://127.0.0.1:8000/docs
```

Tu peux interagir facilement avec tous les endpoints via une interface graphique gÃ©nÃ©rÃ©e automatiquement.

---

## ğŸ› ï¸ DÃ©veloppement et structure

- `scraping/scraper.py` : contient la fonction `scraper_annonces(n_pages)` qui utilise Selenium pour naviguer sur le site.
- `api/main.py` : expose lâ€™API via FastAPI.
- `data/annonces.json` : contient les rÃ©sultats du scraping sous forme de liste d'objets JSON.

---

##  Exemple de rÃ©sultat JSON

```json
[
  {
    "titre": "Appartement s2 Ã  vendre",
    "type": "Appartement",
    "nature": "Vente",
    "rubrique": "Immobilier",
    "gouvernorat": "Tunis",
    "delegation": "La Marsa",
    "localite": "Gammarth",
    "description": "Appartement s2 hst Ã  boumhal",
    "prix": "250 000 TND",
    "date_publication": "2025-01-15",
    "lien": "http://www.tunisie-annonce.com/..."
  }
]
```

---

##  Remarques

- Le scraping utilise Selenium â†’ il ouvre une vraie fenÃªtre Chrome.
- Tu peux rÃ©duire le `time.sleep` dans le script si le chargement est rapide.
